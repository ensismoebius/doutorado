\chapter{Abordagem proposta} \label{chap:propApproach}
	\section{A Base de sinais de soz}
	    \subsection{Coleta dos sinais}
		\par Para a realização desta pesquisa, coletou-se uma série de vozes nos arredores do Instituto de Biociências, Letras e Ciências Exatas da UNESP em São José do Rio Preto, no estado de São Paulo. Foram coletadas amostras de 21 indivíduos, das quais 20 foram usadas já que, em um dos casos, não foi possível coletar todos os dados necessários. Tais gravações se constituem de dígitos em um intervalo de 0 a 9 falados tanto em língua Inglesa quanto na Portuguesa. Os locutores foram escolhidos de acordo com seu sexo e idade de forma que a amostra estudada tenha uma abrangência que cubra desde crianças em época pré-escolar até adultos com idades até os 67 anos dos sexos masculino e feminino.\\
					
		\par As gravações foram realizadas usando-se um \textit{smartfone} Asus modelo \textit{Ze550kl} rodando o sistema operacional \textit{Android 6.0.1} em ambientes distintos com diferentes níveis de ruído ao fundo, garantindo uma boa variabilidade de interferências corriqueiras, caracterizando casos reais. Foram usados arquivos no formato \textit{wave}, descrito no apêndice \ref{chap:waveFile}, sem compressão com quantização de 16 bits e taxa de amostragem de 44100Hz, permitindo, segundo o teorema de Nyquist, que sejam registradas frequências de até 22050Hz.\\
		
		\par Coletados os sinais, os dígitos pronunciados nos mesmos foram separados um-a-um usando uma ferramenta desenvolvida para esse fim, resultando em um total de 410 sinais de voz de diferentes durações temporais que foram rotulados como ``genuínos''. Para cada um deles, foi criado um sinal ``espelho'',  regravado por um segundo dispositivo, um \textit{notebook} Acer modelo  \textit{Travelmate B} com o sistema operacional \textit{Arch GNU/Linux}, caracterizando os 410 sinais rotulados como ``falseados''.

	    \subsection{Organização da base de sinais}
		\par A organização da base de dados se deu por tipo, isto é, genuíno ou falseado, idioma, dígito ditado e interlocutor considerado. Foi criada uma estrutura hierárquica de diretórios de forma a permitir acesso fácil e intuitivo a cada um dos arquivos \textit{wav}, seja por vias automatizadas ou não. Os arquivos falseados residem no diretório ``playback'', enquanto que os genuínos se encontram no diretório ``live''.	Essa organização está ilustrada nas Figuras \ref{fig:directorystructlevel01}, \ref{fig:directorystructlevel02} e \ref{fig:directorystructlevel03}.\\
		
		\par Para facilitar a automatização do processamento, foram criados três arquivos de texto:
		\begin{itemize}
			\item \textit{\textbf{dataSurvey.txt}}: Contêm os dados de idade, sexo e nome do arquivo gerado para cada entrevistado;
			\item \textit{\textbf{inputListLive.txt}}: Uma lista de caminhos para todos os arquivos genuínos;
			\item \textit{\textbf{inputListSpoofing.txt}}: Apresenta uma listagem dos caminhos para todos os arquivos falseados.
		\end{itemize}
	
		\par Apenas para ilustrar, o conteúdo do diretório \textbf{``separated\textfractionsolidus live\textfractionsolidus en\_US\textfractionsolidus 0''} se constitui de vários arquivos do tipo \textit{wave}, cada um identificando o locutor ao qual pertence como exibido na Figura \ref{fig:directorystructlevel03}.

		\begin{figure}[ht]
			\centering
			\caption{Organização da base de dados}
			\subfloat[0.33\textwidth][Base em nível 1]{
				\includegraphics{images/directoryStructLevel01.pdf}
				\label{fig:directorystructlevel01}
			}
			\subfloat[0.33\textwidth][Base em nível 2]{
				\includegraphics{images/directoryStructLevel02.pdf}
				\label{fig:directorystructlevel02}
			}
			\subfloat[0.33\textwidth][Base em nível 3]{
				\includegraphics{images/directoryStructLevel03.pdf}
				\label{fig:directorystructlevel03}
			}
			\label{fig:directorystructlevel010203}
			\\Fonte: Elaborado pelo autor, 2021.
		\end{figure}

	\section{Estrutura da estratégia proposta}
		\par A estratégia proposta para diferenciar sinais de voz genuínos daqueles falseados deu-se conforme ilustrado na Figura \ref{fig_arq}. Particularmente, a metodologia consiste na obtenção dos dados brutos de todos os 410 + 410 = 820 sinais de voz genuínos e falseados, seguida da conversão de cada um deles para um vetor de características correspondente, conforme explicado adiante. Na sequência, os melhores sub-conjuntos de características foram escolhidos com base na Engenharia Paraconsistente. Prosseguindo, separações aleatórias entre os vetores, com proporções diversas, foram realizadas para isolar aqueles destinados ao treinamento ou modelagem do classificador utilizado dos que foram destinados aos testes de classificação. Por fim, os testes realizados e seus resultados são mostrados no Capítulo seguinte.
		
		\input{images/strategicStructure.tex}
		
		\par Conforme mencionado nos Capítulos anteriores, os vetores de características desta abordagem foram obtidos com base na Transformada \textit{Wavelet}, convertendo os sinais de voz do domínio do tempo para o domínio tempo-frequência. Particularmente, nos experimentos detalhados adiante, foram testados os seguintes filtros \textit{wavelet}: Haar, Daubechies de suportes 4 até 76, Symmlets com suportes 8, 16 e 32, Coiflets com suportes 6, 12, 18, 24 e 30, Beylkin com suporte 18 e, ainda, Vaidyanathan de suporte 24.

	\section{Procedimentos}
		\par De modo a garantir a comparação com outros trabalhos se fez necessário adotar várias formas de representar os resultados correspondentes para cada configuração experimental:\\
		\begin{itemize}
			\item Tabela de confusão.
			\item Acurácia e seu respectivo desvio padrão.
			\item EER (Equal Error Rate).
		\end{itemize}
		
		\par No exemplo constituído pela tabela de confusão \ref{tab:confusionMatrixSample} as \textbf{linhas} representam as \textbf{classes estimadas} e as \textbf{colunas} as \textbf{classes verdadeiras}, sendo que:
		\begin{itemize}
			\item \textbf{TP}: quantidade de itens verdadeiros classificados como tal (\textit{True Positive}).
			\item \textbf{TN}: quantidade de itens falsos classificados como tal (\textit{True Negative}).
			\item \textbf{FN}: quantidade de itens verdadeiros classificados como falsos (\textit{False Negative}).
			\item \textbf{FP}: quantidade de itens falsos classificados como verdadeiros (\textit{False Positive}).
		\end{itemize} 
		\input{tables/results/confusionMatrices/confusionMatrixSample.tex}
		
		\par A acurácia usa os valores de \textit{TP}, \textit{TN} e a quantidade de elementos(\textit{N}) para ser calculada como mostrado na Equação \ref{eq:calculoDaAcuracia}.\\
		
		\begin{equation}
			acuracia = \dfrac{TP + TN}{N} \qquad.
			\label{eq:calculoDaAcuracia}
		\end{equation}

		\par Para se calcular o EER se considera os valores de \textit{FP} e \textit{FN} \cite{ghazali2018recent}, a partir desses valores são calculadas as \textit{False Acceptance Rate (\textbf{FAR})} representada na equação \ref{eq:FAR} e \textit{False Rejection Rate (\textbf{FRR})} representada por \ref{eq:FRR} ou \textbf{Taxa de falsos positivos} e \textbf{Taxa de falsos negativos} respectivamente.\\
		
		\begin{equation}
			FAR=\dfrac{FP}{TN+FP} \qquad.
			\label{eq:FAR}
		\end{equation}
		
		\begin{equation}
			FRR=\dfrac{FN}{TP+FN} \qquad.
			\label{eq:FRR}
		\end{equation}
				
		\par São calculadas tabelas de confusão por um número suficiente de vezes até que \textbf{\textit{FAR} seja igual \textit{FRR}}, a cada ciclo os vetores de características são comutados de forma aleatória para que se consiga valores diferentes, neste trabalho alguns casos precisaram de mais que 12000 iterações para que se encontrasse uma configuração em que FAR=FRR.\\
		
		\par Em cada iteração os valores de FAR e FRR são guardados em dois vetores, um para cada, então o vetor pertencente a FAR é ordenado de forma crescente e o outro decrescente. Esses pontos desenhados no gráfico com uma linha que divide o plano do mesmo ao meio tal que $x=y$ constituem o que se convencionou chamar de gráfico de \textit{Detection Error Tradeoff (DET)} ou, em tradução livre, \textbf{gráfico para balanceamento de erros}.\\
		
		\par O efetivo valor de \textbf{ERR se encontra na intersecção da reta $x=y$} com a curva definida por FAR e FRR, por isso o cálculo de um valor único como demonstrado no Algoritmo \ref{lst:EERAlgo} e na Figura \ref{fig:eeralgo} pois se $x=ERR$ então também $y=ERR$.\\\\
	
		\input{codeListings/EERAlgo.tex}

		\begin{figure}[H]
			\centering
			\caption{Algoritmo para o cálculo do EER}
			\includegraphics[width=1\linewidth]{images/EERAlgo.pdf}
			\label{fig:eeralgo}
			\\Fonte: Elaborado pelo autor, 2021.
		\end{figure}
	
		\subsection{Procedimento 01: Filtros \textit{wavelet}, escalas Bark e Mel}
		\label{chap:propApproach:sec:Experimento01}
		\par O objetivo deste procedimento é o de verificar, segundo a Engenharia Paraconsistente, qual das combinações entre as escalas BARK ou MEL e as várias \textit{wavelets} consideradas geram os vetores de características mais propícios, ou seja, que atraem o ponto $(G_1,G_2)$ para uma posição mais próxima do vértice $(1,0)$ do plano paraconsistente, conforme mencionado no Capítulo anterior. \\
				
		\par As transformações \textit{wavelet-packet} foram realizadas, com os diversos filtros mencionados, até  o máximo nível possível, implicando máxima resolução em frequência para que, após isso, as amostras dos sinais transformados fossem agrupadas visando corresponder aos intervalos espectrais definidos nas escalas BARK e MEL. Naquela escala, os vetores de características foram constituídos de 24 coeficientes, diferentemente, nesta escala, os vetores de características foram formados com 13 coeficientes devido à derivação do sinal ao final do processo de geração. O Algoritmo \ref{lst:experiment01Algo} e Figura \ref{fig:experiment01Algo} contém a descrição de tais procedimentos.\\

		\input{codeListings/experiment01Algo.tex}
			
		\begin{figure}[H]
			\centering
			\caption{Algoritmo que caracteriza o Procedimento 01}
			\includegraphics[width=1\linewidth]{images/AlgoProcedure01.pdf}
			\label{fig:experiment01Algo}
			\\Fonte: Elaborado pelo autor, 2021.
		\end{figure}
		
		\par Registre-se que, antes da aplicação da transformada \textit{wavelet-packet}, foi necessária uma normalização de valores do sinal entre os intervalos -1 e 1 seguida de um redimensionamento para que houvesse um comprimento correspondente a uma potência de 2, como indicado na equação \ref{eq:optimalSize}. Isso é necessário para que não haja perdas de trechos de voz ao final da transformação, pois a transformada \textit{wavelet} realiza um \textit{downsampling} de ordem 2, ou seja, em cada nível de decomposição o tamanho do vetor do sinal é diminuído pela metade. Caso haja um comprimento diferente do citado, em alguma parte do processo a divisão não será inteira fazendo com que algumas amostras dos sinais sejam perdidas.
				
		\par Para ajustar o tamanho do sinal de voz sob análise, foi usada a Equação \ref{eq:optimalSize}, na qual \textit{\textbf{proxInt}} é uma função que retorna o próximo número inteiro do argumento real. Por exemplo, $proxInt(1,5) = 2$.

		\begin{equation}
			tamanhoOtimo=2^{proxInt(\log_{2}tamanho)}
			\label{eq:optimalSize}
		\end{equation} 
		
		\par Após o redimensionamento do tamanho do sinal, o nível máximo de transformações é dado pela Equação \ref{eq:maxWaveletTransf}. 
				
		\begin{equation}
			maxTrans=\log_{2}(tamanhoOtimo) \qquad.
			\label{eq:maxWaveletTransf}
		\end{equation}
		
		\subsection{Procedimento 02 - Classificações baseadas em distâncias}
		\label{chap:propApproach:sec:Experimento02}
		\par O objetivo deste procedimento é verificar, considerando as melhores combinações descobertas pelo procedimento anterior, a acurácia de classificadores \textit{pattern-matching} por distâncias Euclidiana e Manhattan. Nesta fase, os vetores de características gerados pelo Procedimento 01 são fornecidos aos classificadores para as mensurações devidas.
				
		\par Objetivando avaliar o comportamento dos classificadores com proporções múltiplas de 10\% da base de dados reservadas para modelagem até o limite de 50\%, e o restante para testes, definiu-se que, para cada proporção, o sorteio aleatório para escolha dos vetores de características e o treinamento dos classificadores seria executado $n=t \cdot \frac{t+1}{2}$ vezes, sendo $t$ o número máximo de testes que podem ser realizados com uma certa porcentagem dos vetores, em outras palavras, \textbf{a cada ciclo de treinamento e classificação os vetores nas amostras falseadas e genuínas foram sorteados aleatoriamente de acordo com a porcentagem vigente.}
				
		\par Para cada porcentagem foram coletadas as melhores e as piores acurácias assim como suas respectivas matrizes de confusão, e assim, calculadas suas \textit{EERs} conforme consta no Capítulo seguinte. No Algoritmo \ref{lst:experiment02Algo} e na Figura \ref{fig:experiment02Algo}, os passos estão detalhados.
		
		\par Essencialmente, este Procedimento 02 consiste em mensurar as distâncias entre cada vetor de características isolado para testes em relação à cada um dos vetores de características isolados para a modelagem, selecionando-se a menor delas. Em seguida, classifica-se o vetor de características que pertence aos testes e está sob análise, como pertencente a uma das classes dos vetores de modelagem selecionados.   

		\begin{figure}[H]
			\centering
			\caption{Algoritmo que caracteriza o Procedimento 02}
			\includegraphics[width=.75\linewidth]{images/AlgoProcedure02}
			\label{fig:experiment02Algo}
			\\Fonte: Elaborado pelo autor, 2021.
		\end{figure}
		
		\input{codeListings/experiment02Algo.tex}

		\subsection{Procedimento 03 - classificações baseadas na SVM}
		\label{chap:propApproach:sec:Experimento03}
		\par Considerando as melhores combinações descobertas durante o Procedimento 01, esta etapa visa medir a acurácia de uma SVM na separação das classes. O referido classificador foi escolhido, pois, estudos anteriores comprovam a sua eficácia para classificação binária \cite{bennett2000support}. \\
		
		\par Particularmente, a estrutura da SVM utilizada foi definida da seguinte forma e de acordo com a Figura \ref{fig:3layersSVM}: 
		\begin{itemize}
			\item três camadas, sendo a primeira de entrada, com elementos passivos, a segunda com elementos ativos não-lineares de núcleos Gaussianos e a terceira, isto é, a de saída, com um elemento ativo linear; 
			
			\item inexistem pesos entre a camada de entrada e a camada intermediária, implicando que a saída de cada elemento da camada de entrada conecta-se com todas as entradas de cada elemento da camada intermediária, mantendo incólumes os valores propagados;

			\item a saída de cada elemento da camada intermediária conecta-se com o único elemento da camada de saída por meio dos pesos $p_0, p_1, .... p_{X-1}$;

			\item o valor de saída consiste na combinação linear dos pesos com os valores recebidos como entrada da camada de saída, isto é, os valores de saída da camada intermediária.
		\end{itemize}

		\input{images/3layersSVM.tex}

		\par Foram utilizados, na camada de entrada, um número de elementos igual a dimensão do vetor de características sendo considerado. Na camada intermediária, o número de elementos ativos não-lineares foi igual ao número de casos de treinamento, visando facilitar o procedimento que, em tal caso, implica na solução direta de um sistema linear quadrado, isto é, possível e determinado \cite{poole2014linear}.\\
		
		\par O treinamento da SVM consiste em, numa primeira etapa não-supervisionada, ajustar os parâmetros das funções Gaussianas da camada intermediária. Posteriormente, com base no sistema linear mencionado, os pesos foram encontrados com base em uma abordagem supervisionada, utilizando-se os rótulos -1 e 1 para os sinais falseados e genuínos, respectivamente.
		
		\par Todos os arranjos para a seleção dos vetores de treinamento e testes, assim como demais detalhes,   são idênticos àqueles do procedimento 02 e encontram-se listados no Algoritmo \ref{lst:experiment03Algo} e na Figura \ref{fig:experiment03Algo}.\\
		
		\input{codeListings/experiment03Algo.tex}
		
		\begin{figure}[h]
			\centering
			\caption{Algoritmo que caracteriza o Procedimento 03}
			\includegraphics[width=0.9\linewidth]{images/AlgoProcedure03}
			\label{fig:experiment03Algo}
			\\Fonte: Elaborado pelo autor, 2021.
		\end{figure}

        \par Os testes e resultados dos experimentos descritos neste Capítulo encontram-se no Capítulo seguinte.
